# GRU-TD3 åˆ†ç¦»å¼æ¶æ„å¿«é€Ÿå‚è€ƒ

## æ ¸å¿ƒæ¦‚å¿µ

### ğŸ¯ è®¾è®¡ç›®æ ‡
å°†GRUé¢„æµ‹å±‚åˆ†ç¦»å‡ºæ¥ï¼Œä½œä¸ºActorå’ŒCriticçš„å…±äº«é¦–å±‚ï¼Œåœ¨æ—¶å»¶åœºæ™¯ä¸‹è¿›è¡Œåœ¨çº¿è®­ç»ƒã€‚

### ğŸ”‘ å…³é”®ç‰¹æ€§
1. **GRUé¢„æµ‹å™¨ç‹¬ç«‹è®­ç»ƒ**ï¼šè¾“å…¥æ—¶å»¶åºåˆ—ï¼Œé¢„æµ‹çœŸå®æœªæ¥çŠ¶æ€
2. **å…±äº«æ¶æ„**ï¼šActorå’ŒCriticå…±ç”¨åŒä¸€ä¸ªGRUé¢„æµ‹å™¨
3. **å‚æ•°å†»ç»“**ï¼šè®­ç»ƒActor/Criticæ—¶ï¼ŒGRUå‚æ•°ä¸æ›´æ–°
4. **åœ¨çº¿å­¦ä¹ **ï¼šæ¯ä¸ªepisodeåæ›´æ–°GRUé¢„æµ‹å™¨
5. **æ³¨æ„åŠ›æœºåˆ¶**ï¼šè‡ªé€‚åº”é€‰æ‹©é‡è¦çš„é¢„æµ‹æ—¶é—´æ­¥

## å¿«é€Ÿå¼€å§‹

### æœ€å°ç¤ºä¾‹ä»£ç 

```python
from env import ElectromagneticDamperEnv
from TD3 import Gru_TD3Agent
from nn import Gru_ReplayBuffer, GruPredictorBuffer
from train import train_td3
import fx
import numpy as np

# åˆ›å»ºç¯å¢ƒ
env = ElectromagneticDamperEnv(A, B, C, D, E, Ts=0.001, T=10,
    z_func=fx.sin_wave(0.01, 1.0),
    r_func=fx.tolerance_if_rf(1e-3),
    obs_indices=[3], use_dt_noise=True)

# åˆ›å»ºä»£ç†
agent = Gru_TD3Agent(
    state_dim=1, action_dim=1, hidden_dim=128,
    seq_len=10, pre_seq_len=5,
    gru_predictor_lr=1e-3,  # é‡è¦ï¼
    delay_enabled=True, delay_step=5
)

# åˆ›å»ºå›æ”¾æ± 
replay_buffer = Gru_ReplayBuffer(100000, 64, 10)
predictor_buffer = GruPredictorBuffer(100000, 64, 10, 5)  # é‡è¦ï¼

# è®­ç»ƒ
train_td3(env, agent, replay_buffer,
    predictor_buffer=predictor_buffer,  # å¿…é¡»ä¼ å…¥
    n_episodes=200)
```

## APIå‚è€ƒ

### GruPredictor
```python
GruPredictor(
    state_dim=1,        # çŠ¶æ€ç»´åº¦
    hidden_dim=64,      # GRUéšè—å±‚ç»´åº¦
    num_layers=1,       # GRUå±‚æ•°
    pre_seq_len=5       # é¢„æµ‹æœªæ¥æ—¶é—´æ­¥æ•°
)
```

**æ–¹æ³•ï¼š**
- `forward(state_seq)` â†’ `(predicted_seq, hidden_seq)`
  - è¾“å…¥ï¼š`[batch, seq_len, state_dim]`
  - è¾“å‡ºï¼š`[batch, pre_seq_len, state_dim]`

### Gru_Actor / Gru_Critic
```python
Gru_Actor(
    state_dim=1,
    action_dim=1,
    hidden_dim=64,
    action_bound=5.0,
    seq_len=10,
    gru_predictor=None  # å¿…é¡»ä¼ å…¥å…±äº«çš„GruPredictorï¼
)
```

**å…³é”®æ–¹æ³•ï¼š**
- `freeze_gru()` - å†»ç»“GRUå‚æ•°
- `unfreeze_gru()` - è§£å†»GRUå‚æ•°ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰

### GruPredictorBuffer
```python
GruPredictorBuffer(
    capacity=100000,
    batch_size=64,
    seq_len=10,         # è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆæ—¶å»¶ï¼‰
    pre_seq_len=5       # é¢„æµ‹é•¿åº¦ï¼ˆæœªæ¥ï¼‰
)
```

**æ–¹æ³•ï¼š**
- `add_from_full_history(full_state_history, delay)`
  - ä»å®Œæ•´å†å²æå–è®­ç»ƒæ ·æœ¬
  - `full_state_history`ï¼šæ— æ—¶å»¶çš„çœŸå®çŠ¶æ€åˆ—è¡¨
  - `delay`ï¼šå»¶è¿Ÿæ­¥æ•°

- `sample()` â†’ `(delayed_seqs, true_future_seqs)`
  - è¿”å›ä¸€æ‰¹è®­ç»ƒæ•°æ®

### Gru_TD3Agent
```python
Gru_TD3Agent(
    # ... åŸºæœ¬å‚æ•°åŒTD3Agent ...
    seq_len=10,
    gru_layers=1,
    pre_seq_len=5,
    gru_predictor_lr=1e-3,  # æ–°å¢ï¼šGRUé¢„æµ‹å™¨å­¦ä¹ ç‡
    delay_enabled=True,
    delay_step=5
)
```

**æ–°å¢æ–¹æ³•ï¼š**
- `update_gru_predictor(predictor_buffer)` â†’ `predictor_loss`
  - å•ç‹¬æ›´æ–°GRUé¢„æµ‹å™¨
  - è¿”å›MSEæŸå¤±å€¼

### train_td3
```python
train_td3(
    env, agent, replay_buffer,
    predictor_buffer=None,      # GRUé¢„æµ‹å™¨å›æ”¾æ± 
    predictor_update_freq=1,    # æ›´æ–°é¢‘ç‡ï¼ˆæ­¥ï¼‰
    # ... å…¶ä»–å‚æ•° ...
)
```

## æ•°æ®æµ

### è®­ç»ƒé˜¶æ®µ
```
ç¯å¢ƒ â†’ è§‚æµ‹åºåˆ—ï¼ˆå¸¦æ—¶å»¶ï¼‰ â†’ Actor/Critic â†’ åŠ¨ä½œ
  â†“
å®Œæ•´çŠ¶æ€å†å²ï¼ˆæ— æ—¶å»¶ï¼‰ â†’ GruPredictorBuffer
  â†“
[æ—¶å»¶åºåˆ—, çœŸå®æœªæ¥] â†’ GRU Predictorè®­ç»ƒ â†’ MSE Loss
```

### GRUé¢„æµ‹å™¨è®­ç»ƒ
```
è¾“å…¥ï¼šçŠ¶æ€åºåˆ—[t-delay-seq_len : t-delay]ï¼ˆæ—¶å»¶ï¼‰
ç›®æ ‡ï¼šçŠ¶æ€åºåˆ—[t : t+pre_seq_len]ï¼ˆçœŸå®æœªæ¥ï¼‰
æŸå¤±ï¼šMSE(é¢„æµ‹, çœŸå®)
```

### Actor/Criticæ¨ç†
```
è¾“å…¥ï¼šæ—¶å»¶çŠ¶æ€åºåˆ—
  â†“
GRUé¢„æµ‹å™¨ï¼ˆå†»ç»“ï¼‰â†’ é¢„æµ‹æœªæ¥çŠ¶æ€åºåˆ—
  â†“
æ³¨æ„åŠ›å±‚ â†’ åŠ æƒä¸Šä¸‹æ–‡å‘é‡
  â†“
å…¨è¿æ¥å±‚ â†’ åŠ¨ä½œ/Qå€¼
```

## å‚æ•°è®¾ç½®å»ºè®®

### åºåˆ—é•¿åº¦
```python
seq_len = 10           # è¾“å…¥å†å²é•¿åº¦ï¼š5-15åˆé€‚
pre_seq_len = 5        # é¢„æµ‹é•¿åº¦ï¼šå»ºè®®â‰ˆdelay_step
delay_step = 5         # å»¶è¿Ÿæ­¥æ•°ï¼šæ ¹æ®å®é™…ç³»ç»Ÿ
```

**è§„åˆ™ï¼š** `seq_len + delay_step - 1 + pre_seq_len â‰¤ episode_length`

### å­¦ä¹ ç‡
```python
actor_lr = 3e-4        # Actorå­¦ä¹ ç‡
critic_lr = 3e-4       # Criticå­¦ä¹ ç‡
gru_predictor_lr = 1e-3  # GRUé¢„æµ‹å™¨ï¼šå¯ä»¥è®¾ç½®æ›´å¤§
```

### éšè—å±‚
```python
hidden_dim = 128       # 64-256ï¼Œæ ¹æ®é—®é¢˜å¤æ‚åº¦
gru_layers = 1         # 1-2å±‚ï¼Œå¤ªæ·±å®¹æ˜“è¿‡æ‹Ÿåˆ
```

### å›æ”¾æ± 
```python
capacity = 100000      # ç»éªŒæ± å®¹é‡
batch_size = 64        # æ‰¹æ¬¡å¤§å°ï¼š32-128
min_buffer_size = 1000 # å¼€å§‹è®­ç»ƒçš„æœ€å°æ ·æœ¬æ•°
```

## è®­ç»ƒç›‘æ§

### å…³é”®æŒ‡æ ‡
1. **predictor_loss**: GRUé¢„æµ‹å™¨çš„MSEæŸå¤±
   - æœŸæœ›ï¼šéšè®­ç»ƒä¸‹é™å¹¶è¶‹äºç¨³å®š
   - å¼‚å¸¸ï¼šæŒç»­ä¸Šå‡æˆ–éœ‡è¡ â†’ æ£€æŸ¥å­¦ä¹ ç‡

2. **actor_loss**: ActoræŸå¤±
   - æœŸæœ›ï¼šè´Ÿå€¼ï¼Œç»å¯¹å€¼é€æ¸å¢å¤§
   - å¼‚å¸¸ï¼šNaN â†’ æ£€æŸ¥æ¢¯åº¦è£å‰ª

3. **critic_loss**: CriticæŸå¤±
   - æœŸæœ›ï¼šä¸‹é™åç¨³å®šåœ¨è¾ƒå°å€¼
   - å¼‚å¸¸ï¼šä¸ä¸‹é™ â†’ æ£€æŸ¥å¥–åŠ±å‡½æ•°è®¾è®¡

4. **simu_reward**: æµ‹è¯•å›åˆå¥–åŠ±
   - æœŸæœ›ï¼šé€æ¸æå‡
   - å¼‚å¸¸ï¼šä¸æå‡ â†’ å¯èƒ½æ¬ æ‹Ÿåˆæˆ–ç¯å¢ƒé—®é¢˜

### æ—¥å¿—æ ¼å¼
```csv
episode, rewards, critic_loss, actor_loss, epsilon, simu_reward, predictor_loss
```

## å¸¸è§é—®é¢˜

### Q1: GRUé¢„æµ‹å™¨æŸå¤±ä¸ä¸‹é™ï¼Ÿ
**åŸå› ï¼š**
- å­¦ä¹ ç‡è¿‡å°
- æ•°æ®é‡ä¸è¶³
- åºåˆ—é•¿åº¦ä¸åŒ¹é…

**è§£å†³ï¼š**
```python
# å¢å¤§å­¦ä¹ ç‡
gru_predictor_lr=5e-3

# å¢åŠ é¢„æµ‹å™¨æ›´æ–°é¢‘ç‡
predictor_update_freq=1

# æ£€æŸ¥æ•°æ®
print(len(predictor_buffer))  # åº”è¯¥æœ‰è¶³å¤Ÿæ ·æœ¬
```

### Q2: Actor/Criticè®­ç»ƒä¸ç¨³å®šï¼Ÿ
**åŸå› ï¼š**
- GRUé¢„æµ‹ä¸å‡†
- æ³¨æ„åŠ›æœºåˆ¶å¤±æ•ˆ
- å­¦ä¹ ç‡è¿‡å¤§

**è§£å†³ï¼š**
```python
# å…ˆå……åˆ†è®­ç»ƒGRUé¢„æµ‹å™¨
for _ in range(1000):
    agent.update_gru_predictor(predictor_buffer)

# é™ä½Actor/Criticå­¦ä¹ ç‡
actor_lr=1e-4, critic_lr=1e-4

# å¯ç”¨æ¢¯åº¦è£å‰ª
clip_grad=True
```

### Q3: å¦‚ä½•è¯„ä¼°GRUé¢„æµ‹è´¨é‡ï¼Ÿ
```python
# æ‰‹åŠ¨æµ‹è¯•é¢„æµ‹å™¨
delayed_seqs, true_seqs = predictor_buffer.sample()
predicted_seqs, _ = agent.gru_predictor(delayed_seqs)
mse = F.mse_loss(predicted_seqs, true_seqs)
print(f"é¢„æµ‹MSE: {mse.item()}")

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
import matplotlib.pyplot as plt
plt.plot(true_seqs[0].cpu().numpy(), label='çœŸå®')
plt.plot(predicted_seqs[0].detach().cpu().numpy(), label='é¢„æµ‹')
plt.legend()
plt.show()
```

### Q4: predictor_bufferåº”è¯¥å¤šå¤§ï¼Ÿ
**å»ºè®®ï¼š**
- æœ€å°ï¼š`min_buffer_size` (1000)
- æ¨èï¼š`10 * n_episodes * (T/Ts)` 
- å¯¹äºT=10, Ts=0.001, 200 episodes: ~200,000

```python
capacity = 200000  # è¶³å¤Ÿå­˜å‚¨å¤šä¸ªepisodeçš„æ ·æœ¬
```

### Q5: å¦‚ä½•è®¾ç½®pre_seq_lenï¼Ÿ
**è§„åˆ™ï¼š**
- å¤ªå°ï¼šä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆè¡¥å¿æ—¶å»¶
- å¤ªå¤§ï¼šè®¡ç®—é‡å¤§ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ

**å»ºè®®ï¼š**
```python
# æ–¹æ¡ˆ1ï¼šä¸å»¶è¿Ÿæ­¥æ•°ç›¸ç­‰
pre_seq_len = delay_step

# æ–¹æ¡ˆ2ï¼šç•¥å¤§äºå»¶è¿Ÿ
pre_seq_len = int(delay_step * 1.5)

# æ–¹æ¡ˆ3ï¼šæ ¹æ®æ§åˆ¶å‘¨æœŸ
pre_seq_len = int(0.1 / Ts)  # é¢„æµ‹0.1ç§’
```

## è°ƒè¯•æŠ€å·§

### 1. éªŒè¯æ•°æ®æµ
```python
# æ£€æŸ¥predictor_bufferæ•°æ®
delayed, future = predictor_buffer.sample()
print(f"æ—¶å»¶åºåˆ—: {delayed.shape}")  # [batch, seq_len, state_dim]
print(f"æœªæ¥åºåˆ—: {future.shape}")   # [batch, pre_seq_len, state_dim]
```

### 2. æ£€æŸ¥å‚æ•°å†»ç»“
```python
# éªŒè¯GRUå‚æ•°æ˜¯å¦è¢«å†»ç»“
for name, param in agent.actor.gru_predictor.named_parameters():
    print(f"{name}: requires_grad={param.requires_grad}")  # åº”è¯¥æ˜¯False
```

### 3. ç›‘æ§æ¢¯åº¦
```python
# åœ¨train.pyçš„æ›´æ–°å¾ªç¯ä¸­æ·»åŠ 
if step_count % 100 == 0:
    for name, param in agent.gru_predictor.named_parameters():
        if param.grad is not None:
            print(f"{name} grad: {param.grad.norm().item()}")
```

### 4. å•æ­¥æµ‹è¯•
```python
# æµ‹è¯•å•æ­¥å‰å‘ä¼ æ’­
state_seq = torch.randn(1, 10, 1).to(device)
action = agent.actor(state_seq)
print(f"åŠ¨ä½œè¾“å‡º: {action}")  # åº”è¯¥åœ¨[-action_bound, action_bound]
```

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡æ›´æ–°
```python
# æ¯ä¸ªepisodeç»“æŸåæ‰¹é‡æ›´æ–°GRUé¢„æµ‹å™¨
if (episode + 1) % 5 == 0:
    for _ in range(100):
        agent.update_gru_predictor(predictor_buffer)
```

### 2. é¢„è®­ç»ƒ
```python
# å…ˆæ”¶é›†æ•°æ®ï¼Œå†å¼€å§‹RLè®­ç»ƒ
for episode in range(50):  # çº¯æ¢ç´¢
    # ... æ”¶é›†æ•°æ® ...
    predictor_buffer.add_from_full_history(...)

# é¢„è®­ç»ƒGRU
for _ in range(1000):
    agent.update_gru_predictor(predictor_buffer)

# å¼€å§‹RLè®­ç»ƒ
train_td3(...)
```

### 3. å­¦ä¹ ç‡è°ƒåº¦
```python
from torch.optim.lr_scheduler import StepLR

scheduler = StepLR(agent.gru_predictor_optimizer, step_size=50, gamma=0.5)

# åœ¨è®­ç»ƒå¾ªç¯ä¸­
if episode % 10 == 0:
    scheduler.step()
```

## ä¿å­˜ä¸åŠ è½½

### ä¿å­˜
```python
# å®Œæ•´ä¿å­˜ï¼ˆåŒ…æ‹¬GRUé¢„æµ‹å™¨ï¼‰
torch.save({
    'gru_predictor': agent.gru_predictor.state_dict(),
    'actor': agent.actor.state_dict(),
    'critic1': agent.critic1.state_dict(),
    'critic2': agent.critic2.state_dict(),
}, 'checkpoint.pth')
```

### åŠ è½½
```python
# å…ˆåˆ›å»ºagentï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºGRUé¢„æµ‹å™¨ï¼‰
agent = Gru_TD3Agent(...)

# åŠ è½½æƒé‡
checkpoint = torch.load('checkpoint.pth')
agent.gru_predictor.load_state_dict(checkpoint['gru_predictor'])
agent.actor.load_state_dict(checkpoint['actor'])
agent.critic1.load_state_dict(checkpoint['critic1'])
agent.critic2.load_state_dict(checkpoint['critic2'])
```

## æ€»ç»“

### âœ… ä½¿ç”¨æ­¤æ¶æ„çš„åœºæ™¯
- å­˜åœ¨æ˜¾è‘—æ—¶å»¶çš„ç³»ç»Ÿ
- éœ€è¦æ˜¾å¼çŠ¶æ€é¢„æµ‹çš„ä»»åŠ¡
- å¸Œæœ›æé«˜è®­ç»ƒç¨³å®šæ€§
- éœ€è¦åˆ†æé¢„æµ‹è´¨é‡

### âŒ ä¸æ¨èä½¿ç”¨çš„åœºæ™¯
- æ— æ—¶å»¶æˆ–æ—¶å»¶å¯å¿½ç•¥
- çŠ¶æ€å®Œå…¨å¯è§‚æµ‹
- è®¡ç®—èµ„æºå—é™
- éœ€è¦å¿«é€ŸåŸå‹éªŒè¯

### ğŸ¯ æ ¸å¿ƒè¦ç‚¹
1. **å¿…é¡»ä¼ å…¥predictor_buffer**
2. **ç¡®ä¿åºåˆ—é•¿åº¦åŒ¹é…**
3. **ç›‘æ§predictor_loss**
4. **åˆç†è®¾ç½®pre_seq_len**
5. **GRUé¢„æµ‹å™¨å‚æ•°ä¼šè¢«è‡ªåŠ¨å†»ç»“**
