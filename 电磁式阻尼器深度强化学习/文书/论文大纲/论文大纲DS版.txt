问题的背景：（参考文献《时滞影响下压电悬臂梁强化学习振动控制》）
结构的振动会使结构疲劳甚至损坏。为了抑制振动,结构振动控制得到了广泛的研究。
结构的主动控制技术是指通过作动器向系统输入能量,以达到对系统振动进行主动调节或镇定的目的。
强化学习( reinforcement learning, RL) 是一种人工智能技术, 近年来，强化学习凭借数据驱动的无模型特性，在非线性振动控制中展现出潜力

问题的提出：
虽然现在已有很多应用强化学习算法到振动控制的相关研究，但多局限于理想仿真环境或简化实验场景，难以直接迁移至工程实践。
环境复杂性：实际系统普遍存在时滞效应（如压电作动器响应延迟）、采样频率波动（传感器数据采集间隔不稳定）及宽频振动干扰（如随机激励下的多模态共振）；
实时性矛盾：强化学习需迭代计算最优控制力，其耗时可能超过振动系统的动态响应周期，导致控制滞后；
鲁棒性不足：传统算法（如DDPG）对时变参数敏感，在变步长采样环境下易出现策略震荡。
针对上述问题，本文提出一种基于时间感知的深度强化学习振动控制算法，通过融合时间序列特征与动态决策机制，提升复杂环境下的控制精度与稳定性。
因此，本文旨在提出一种基于DDPG/TD3深度强化学习算法的时间感知振动控制算法。

解决问题的关键：
1. 采用GRU（门控循环单元）替代传统全连接网络，增强对时变振动信号的长时依赖建模能力，捕捉宽频振动中的频率漂移特征；
2. 环境建模优化：构建随机变步长采样环境，通过动态调整采样间隔（如0.01~0.1s随机波动）模拟工程中的传感器数据不确定性；
3. 状态维度扩展：将时间戳（采样时刻）与历史控制动作（如前3步输出）纳入状态向量，显式建模“控制-响应”的时滞关联，状态向量设计为：
4. 计算延迟补偿：探索将强化学习决策耗时（即控制算法的计算间隔）作为状态输入，通过动态调整决策频率（如高频振动时缩短计算步长）平衡实时性与精度。

大论文的结构：
1. 引言
    振动控制技术现状与挑战（含传统控制方法局限性分析）；
    强化学习在振动控制中的应用进展（重点综述DDPG/TD3算法的工程适配性）；
    本文研究目标、创新点与论文组织结构。
2. 理论基础
    振动系统建模：压电悬臂梁动力学方程及时滞特性分析；
    强化学习框架：马尔可夫决策过程（MDP）建模、Actor-Critic算法原理（DDPG/TD3核心机制对比）。
3. 时间感知强化学习算法设计
    GRU网络结构与状态向量构建；
    随机变步长环境生成方法；
    时滞补偿策略与决策延迟建模。
4. 仿真实验验证
    实验设置：对比传统PID、DDPG及本文算法在固定时滞/变时滞场景下的抑振效果；
    评价指标：振动幅值衰减率、控制能耗、算法收敛速度。
5. 物理实验验证
    实验平台：压电悬臂梁测试系统（含传感器选型与采样方案）；
    结果分析：不同激励频率（如1-50Hz宽频激励）下的控制性能对比，突出时间感知机制对频率跨度的适应性。
6. 结论与展望
    主要研究结论（量化说明算法优势，如“变时滞场景下抑振效果提升XX%”）；
    局限性与未来方向（如多智能体协同控制、边缘计算部署优化）。
